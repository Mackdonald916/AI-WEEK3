{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c15df6e-9fef-46b8-9094-e53a09ad143e",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33a5104c-4dd0-4bb2-bacf-34fae7b2ae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91de905d-c01e-4343-bcfe-b65e1bf11434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84f4a535-6068-4091-a1c9-d12c8f1cebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n",
      "Processing data...\n"
     ]
    }
   ],
   "source": [
    "# File paths (assuming files are in working directory)\n",
    "train_path = \"train.ft.txt\"\n",
    "test_path = \"test.ft.txt\"\n",
    "\n",
    "# Function to read large files efficiently\n",
    "def read_large_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            yield line\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    print(\"Loading training data...\")\n",
    "    train_lines = []\n",
    "    for i, line in enumerate(read_large_file(train_path)):\n",
    "        if i >= 100000:  # Limit to first 100k lines for memory\n",
    "            break\n",
    "        train_lines.append(line)\n",
    "    \n",
    "    print(\"Loading test data...\")\n",
    "    test_lines = []\n",
    "    for i, line in enumerate(read_large_file(test_path)):\n",
    "        if i >= 20000:  # Limit to first 20k lines\n",
    "            break\n",
    "        test_lines.append(line)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    print(\"Processing data...\")\n",
    "    train_df = pd.DataFrame([line.split(' ', 1) for line in train_lines], columns=['sentiment', 'text'])\n",
    "    test_df = pd.DataFrame([line.split(' ', 1) for line in test_lines], columns=['sentiment', 'text'])\n",
    "    \n",
    "    # Clean the data\n",
    "    train_df['text'] = train_df['text'].str.strip()\n",
    "    test_df['text'] = test_df['text'].str.strip()\n",
    "    \n",
    "    # Convert sentiment labels (__label__1 = negative, __label__2 = positive)\n",
    "    train_df['sentiment'] = train_df['sentiment'].str.replace('__label__', '').map({'1': 'negative', '2': 'positive'})\n",
    "    test_df['sentiment'] = test_df['sentiment'].str.replace('__label__', '').map({'1': 'negative', '2': 'positive'})\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\nERROR: Could not find the files in the working directory.\")\n",
    "    print(\"Please ensure you have both files in your current directory:\")\n",
    "    print(\"- train.ft.txt\")\n",
    "    print(\"- test.ft.txt\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32b4adb4-ca2c-4507-875f-0c72399e063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a smaller sample for demonstration\n",
    "sample_size = 500\n",
    "train_sample = train_df.sample(sample_size, random_state=42)\n",
    "test_sample = test_df.sample(sample_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "900738f8-a40d-489e-84d9-5267b8a3be34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spaCy model...\n"
     ]
    }
   ],
   "source": [
    "# Combine samples for NER analysis\n",
    "reviews = pd.concat([train_sample, test_sample])['text'].tolist()\n",
    "\n",
    "# Load the English language model\n",
    "print(\"Loading spaCy model...\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add entity ruler for product names and brands\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "# Define patterns for common products and brands\n",
    "patterns = [\n",
    "    {\"label\": \"PRODUCT\", \"pattern\": \"Kindle\"},\n",
    "    {\"label\": \"PRODUCT\", \"pattern\": \"Echo\"},\n",
    "    {\"label\": \"PRODUCT\", \"pattern\": \"Fire TV\"},\n",
    "    {\"label\": \"PRODUCT\", \"pattern\": \"Fire Stick\"},\n",
    "    {\"label\": \"PRODUCT\", \"pattern\": \"iPad\"},\n",
    "    {\"label\": \"PRODUCT\", \"pattern\": \"iPhone\"},\n",
    "    {\"label\": \"PRODUCT\", \"pattern\": \"Galaxy\"},\n",
    "    {\"label\": \"PRODUCT\", \"pattern\": \"MacBook\"},\n",
    "    {\"label\": \"PRODUCT\", \"pattern\": \"PlayStation\"},\n",
    "    {\"label\": \"PRODUCT\", \"pattern\": \"Xbox\"},\n",
    "    {\"label\": \"PRODUCT\", \"pattern\": \"Nintendo Switch\"},\n",
    "    {\"label\": \"BRAND\", \"pattern\": [{\"LOWER\": \"amazon\"}]},\n",
    "    {\"label\": \"BRAND\", \"pattern\": [{\"LOWER\": \"apple\"}]},\n",
    "    {\"label\": \"BRAND\", \"pattern\": [{\"LOWER\": \"samsung\"}]},\n",
    "    {\"label\": \"BRAND\", \"pattern\": [{\"LOWER\": \"sony\"}]},\n",
    "    {\"label\": \"BRAND\", \"pattern\": [{\"LOWER\": \"microsoft\"}]},\n",
    "    {\"label\": \"BRAND\", \"pattern\": [{\"LOWER\": \"lg\"}]},\n",
    "    {\"label\": \"BRAND\", \"pattern\": [{\"LOWER\": \"dell\"}]},\n",
    "    {\"label\": \"BRAND\", \"pattern\": [{\"LOWER\": \"hp\"}]},\n",
    "    {\"label\": \"BRAND\", \"pattern\": [{\"LOWER\": \"lenovo\"}]},\n",
    "    {\"label\": \"BRAND\", \"pattern\": [{\"LOWER\": \"logitech\"}]},\n",
    "    {\"label\": \"BRAND\", \"pattern\": [{\"LOWER\": \"bose\"}]}\n",
    "]\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c3079-8947-41f1-a9fa-87a27b0c977a",
   "metadata": {},
   "source": [
    "#### Enhanced sentiment analysis with rule-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35007c77-4322-4ef5-b94e-f8fe1e63780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(doc):\n",
    "    # Define sentiment indicators\n",
    "    positive_words = [\"excellent\", \"amazing\", \"great\", \"love\", \"wonderful\", \n",
    "                     \"awesome\", \"perfect\", \"fantastic\", \"recommend\", \"good\",\n",
    "                     \"best\", \"superb\", \"outstanding\", \"pleased\", \"happy\",\n",
    "                     \"impressed\", \"satisfied\", \"working\", \"fine\", \"nice\"]\n",
    "    \n",
    "    negative_words = [\"terrible\", \"awful\", \"horrible\", \"bad\", \"disappointing\",\n",
    "                     \"poor\", \"waste\", \"broke\", \"broken\", \"return\", \"junk\",\n",
    "                     \"worst\", \"useless\", \"faulty\", \"defective\", \"avoid\",\n",
    "                     \"disgusting\", \"unacceptable\", \"failed\", \"damaged\", \"crap\"]\n",
    "    \n",
    "    # Count positive and negative indicators\n",
    "    positive_count = sum(1 for token in doc if token.text.lower() in positive_words)\n",
    "    negative_count = sum(1 for token in doc if token.text.lower() in negative_words)\n",
    "    \n",
    "    # Check for negation patterns\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.text.lower() in [\"not\", \"n't\", \"never\", \"no\"] and i < len(doc) - 1:\n",
    "            next_token = doc[i+1].text.lower()\n",
    "            if next_token in positive_words:\n",
    "                negative_count += 1\n",
    "                positive_count = max(0, positive_count - 1)\n",
    "            elif next_token in negative_words:\n",
    "                positive_count += 1\n",
    "                negative_count = max(0, negative_count - 1)\n",
    "    \n",
    "    # Determine sentiment\n",
    "    if positive_count > negative_count:\n",
    "        return \"positive\"\n",
    "    elif negative_count > positive_count:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9745909-d6b9-4370-abc5-6832c955d112",
   "metadata": {},
   "source": [
    "#### Process reviews and analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8c39972-f632-4cfb-b2fa-8122c96ecd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing reviews...\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing reviews...\")\n",
    "results = []\n",
    "for review in random.sample(reviews, 50):  # Analyze 50 random reviews for demo\n",
    "    try:\n",
    "        doc = nlp(review)\n",
    "        \n",
    "        # Extract entities (filter for products and brands)\n",
    "        entities = [(ent.text, ent.label_) for ent in doc.ents \n",
    "                   if ent.label_ in [\"PRODUCT\", \"BRAND\", \"ORG\"]]\n",
    "        \n",
    "        # Analyze sentiment\n",
    "        sentiment = analyze_sentiment(doc)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"review\": review,\n",
    "            \"entities\": entities,\n",
    "            \"sentiment\": sentiment\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing review: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d213a41-efed-4066-8220-87599dd92ee9",
   "metadata": {},
   "source": [
    "#### Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f04abb1-6d4a-4d4d-9483-150fad4751a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review Analysis Results:\n",
      "\n",
      "Review 1:\n",
      "Text: Just another excuse to make money: I am sorry but after reading this book, I have to admit that the feminists are right. Men are pigs and the only reason this book was written was for the authors to m...\n",
      "Entities: []\n",
      "Sentiment: positive\n",
      "\n",
      "Review 2:\n",
      "Text: look, have any of you actually written a paper on this book?: well I have, and this book has got to be one of the stupidest things I have ever tried to write about. It is basically about nothing, and ...\n",
      "Entities: [('Allende and Amado', 'ORG')]\n",
      "Sentiment: positive\n",
      "\n",
      "Review 3:\n",
      "Text: Rubbish: I actually thought that Ellen would be funnier. This is just rambling nonsence. Just as though she has scribbled down the first thing that came to mind. Not for me, I'm affraid. I couldn't ge...\n",
      "Entities: []\n",
      "Sentiment: neutral\n",
      "\n",
      "Review 4:\n",
      "Text: AN ARTIST'S LIFE: IRVING STONE HAS HIS READERS RELIVE VINCENT VAN GOGH'S LIFE.AFTER READING THE BOOK YOU CAN EASILY APPRECIATE THE TUMULTOUS LIFE THIS ARTIST HAD.THE AURTHOR HAS USED CERTAIN FICTIONAL...\n",
      "Entities: []\n",
      "Sentiment: neutral\n",
      "\n",
      "Review 5:\n",
      "Text: Not bad...: Since I drive a hatchback ('04 Pontiac Vibe) with room for a couple of bikes in the back, I don't have a ton of experience with bike racks. I recently moved 300 miles to another state, and...\n",
      "Entities: [('Surly Cross Check', 'ORG'), ('Trek', 'ORG')]\n",
      "Sentiment: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nReview Analysis Results:\\n\")\n",
    "for i, result in enumerate(results[:5], 1):  # Show first 5 for brevity\n",
    "    print(f\"Review {i}:\")\n",
    "    print(f\"Text: {result['review'][:200]}...\")  # Print first 200 chars\n",
    "    print(f\"Entities: {result['entities']}\")\n",
    "    print(f\"Sentiment: {result['sentiment']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3452d4c2-cf33-4b83-a327-373bc497ce12",
   "metadata": {},
   "source": [
    "#### Visualize NER for a sample review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62457f4c-eea7-4d23-8c75-9f800c391f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Review NER Visualization:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Thought-provoking, fine acting: I really enjoyed \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The Life of David Gale\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       ", although the editing made the story feel very rushed. I love \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kevin Spacey\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", and he gave another compelling performance in this movie. I didn't much care for the casting of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kate Winslet\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", though she too did a good job. I love how the movie keeps the audience guessing right up until the end. VERY strong political statements are made and really hit you over the head, but since it is supposed to be from this man's perspective, even this point can be explained and justified.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_review = random.choice(reviews)\n",
    "doc = nlp(sample_review)\n",
    "print(\"\\nSample Review NER Visualization:\")\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde869d-6b12-4026-9a9e-c0d26021e0a7",
   "metadata": {},
   "source": [
    "#### Entity frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7793418-9802-4665-a868-82bac7da4222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Most Common Entities:\n",
      "ORG: Lennie - 4 occurrences\n",
      "ORG: KoRn - 2 occurrences\n",
      "BRAND: Amazon - 2 occurrences\n",
      "ORG: American Idol - 2 occurrences\n",
      "ORG: Allende and Amado - 1 occurrences\n",
      "ORG: Surly Cross Check - 1 occurrences\n",
      "ORG: Trek - 1 occurrences\n",
      "ORG: WIN XP - 1 occurrences\n",
      "ORG: Motorola Bluetooth - 1 occurrences\n",
      "ORG: Warner Home Video - 1 occurrences\n"
     ]
    }
   ],
   "source": [
    "entity_freq = defaultdict(int)\n",
    "for result in results:\n",
    "    for entity, label in result['entities']:\n",
    "        entity_freq[(entity, label)] += 1\n",
    "\n",
    "print(\"\\nTop 10 Most Common Entities:\")\n",
    "for (entity, label), count in sorted(entity_freq.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{label}: {entity} - {count} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6f2b5-d81d-400d-92cc-304fd61206a1",
   "metadata": {},
   "source": [
    "#### Sentiment distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de30cd-2a60-4bf9-9812-a78c6e946105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Distribution:\n",
      "positive: 28 reviews\n",
      "neutral: 15 reviews\n",
      "negative: 7 reviews\n"
     ]
    }
   ],
   "source": [
    "sentiment_counts = defaultdict(int)\n",
    "for result in results:\n",
    "    sentiment_counts[result['sentiment']] += 1\n",
    "\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    print(f\"{sentiment}: {count} reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8389ff53-c793-4543-8874-b1c144d1d9b2",
   "metadata": {},
   "source": [
    "#### Compare our sentiment analysis with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d2906-b631-4327-9e45-7a5569773094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing with Ground Truth Sentiment:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComparing with Ground Truth Sentiment:\")\n",
    "comparison_results = []\n",
    "for result in results:\n",
    "    # Find the review in our dataframe to get ground truth\n",
    "    ground_truth = None\n",
    "    for df in [train_sample, test_sample]:\n",
    "        match = df[df['text'].str.contains(result['review'][:30], regex=False, na=False)]  # Match first 30 chars\n",
    "        if not match.empty:\n",
    "            ground_truth = match.iloc[0]['sentiment']\n",
    "            break\n",
    "    \n",
    "    if ground_truth:\n",
    "        comparison_results.append({\n",
    "            \"our_sentiment\": result['sentiment'],\n",
    "            \"true_sentiment\": ground_truth\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d385e8cf-8e4c-4afa-a1a1-b3aa55a57741",
   "metadata": {},
   "source": [
    "#### Calculate accuracy if we have comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe12cd6-baca-4c3a-9d2f-392cd3f97085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our sentiment analysis accuracy: 48.00% (24/50)\n",
      "\n",
      "Example Comparisons:\n",
      "Predicted: positive | Actual: negative\n",
      "Predicted: positive | Actual: negative\n",
      "Predicted: neutral | Actual: negative\n"
     ]
    }
   ],
   "source": [
    "if comparison_results:\n",
    "    correct = sum(1 for res in comparison_results \n",
    "                if res['our_sentiment'] == res['true_sentiment'])\n",
    "    total = len(comparison_results)\n",
    "    print(f\"\\nOur sentiment analysis accuracy: {correct/total:.2%} ({correct}/{total})\")\n",
    "    \n",
    "    # Show some examples\n",
    "    print(\"\\nExample Comparisons:\")\n",
    "    for res in comparison_results[:3]:\n",
    "        print(f\"Predicted: {res['our_sentiment']} | Actual: {res['true_sentiment']}\")\n",
    "else:\n",
    "    print(\"Could not match reviews with ground truth for comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ad12d-e11f-4786-9c9d-46914fd778d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
